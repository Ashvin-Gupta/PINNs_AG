{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "#sys.path.append(dir_path)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import deepxde as dde # version 0.11 or higher\n",
    "from deepxde.backend import tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDE Parameters (initialized for 1D PINN)\n",
    "\n",
    "input = 3\n",
    "num_hidden_layers = 5\n",
    "hidden_layer_size = 60\n",
    "num_domain = 40000\n",
    "num_boundary = 4000\n",
    "epochs_main = 150000\n",
    "output = 2 # network input size \n",
    "        \n",
    "## Training Parameters\n",
    "num_domain = 20000 # number of training points within the domain\n",
    "num_boundary = 1000 # number of training boundary condition points on the geometry boundary\n",
    "num_test = 1000 # number of testing points within the domain\n",
    "MAX_MODEL_INIT = 16 # maximum number of times allowed to initialize the model\n",
    "MAX_LOSS = 0.1 # upper limit to the initialized loss\n",
    "epochs_init = 15000 # number of epochs for training initial phase\n",
    "epochs_main = 10000 # number of epochs for main training phase\n",
    "lr = 0.0005 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.01\n",
    "b = 0.15\n",
    "D = 0.1\n",
    "k = 8\n",
    "mu_1 = 0.2\n",
    "mu_2 = 0.3\n",
    "epsilon = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"data_2d_corner.mat\"\n",
    "file_name = \"Spiral_Marta.mat\"\n",
    "\n",
    "data = scipy.io.loadmat(file_name,squeeze_me=True)\n",
    "t, x, y, Vsav, Wsav = data[\"t\"], data[\"x\"], data[\"y\"], data[\"Vsav\"], data[\"Wsav\"]\n",
    "\n",
    "## Geometry Parameters\n",
    "min_x = x[0]\n",
    "max_x = x[-1]\n",
    "min_y = y[0]\n",
    "max_y = y[-1]\n",
    "min_t = y[0]\n",
    "max_t = t[-1]\n",
    "spacing = x[1]-x[0]\n",
    "# print(spacing)\n",
    "\n",
    "X, T, Y = np.meshgrid(x,t,y)\n",
    "Y = Y.reshape(-1, 1)\n",
    "\n",
    "max_t = np.max(t)\n",
    "max_x = np.max(x)        \n",
    "X = X.reshape(-1, 1)\n",
    "T = T.reshape(-1, 1)\n",
    "V = Vsav.reshape(-1, 1)\n",
    "W = Wsav.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_x = np.hstack((X, Y, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IC_func(observe_train, v_train):\n",
    "        \n",
    "        T_ic = observe_train[:,-1].reshape(-1,1)\n",
    "        idx_init = np.where(np.isclose(T_ic,1))[0]\n",
    "        v_init = v_train[idx_init]\n",
    "        observe_init = observe_train[idx_init]\n",
    "        return dde.PointSetBC(observe_init,v_init,component=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_func_2d(x, on_boundary):\n",
    "    return on_boundary and ~(x[0:2]==[min_x,min_y]).all() and  ~(x[0:2]==[min_x,max_y]).all() and ~(x[0:2]==[max_x,min_y]).all()  and  ~(x[0:2]==[max_x,max_y]).all() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BC_func(geomtime):\n",
    "        bc = dde.NeumannBC(geomtime, lambda x:  np.zeros((len(x), 1)), boundary_func_2d, component=0)\n",
    "        return bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_train, observe_test, v_train, v_test, w_train, w_test = train_test_split(observe_x,V,W,test_size=0.8)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = dde.geometry.Rectangle([min_x,min_y], [max_x,max_y])\n",
    "timedomain = dde.geometry.TimeDomain(min_t, max_t)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Boundary Conditions\n",
    "bc = BC_func(geomtime)\n",
    "\n",
    "## Define Initial Conditions\n",
    "ic = IC_func(observe_train, v_train)\n",
    "    \n",
    "## Model observed data\n",
    "observe_v = dde.PointSetBC(observe_train, v_train, component=0)\n",
    "input_data = [bc, ic, observe_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = dde.maps.FNN([input] + [hidden_layer_size] * num_hidden_layers + [output], \"tanh\", \"Glorot uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_2D(x, y):\n",
    "#     print(y.shape)\n",
    "#     print(x.shape)\n",
    "    \n",
    "    V, W = y[:, 0:1], y[:, 1:2]\n",
    "#     print(V)\n",
    "#     print(W)\n",
    "#     print(dde.grad.hessian(y, x, component=0, i=0, j=0))\n",
    "#     print(dde.grad.jacobian(y, x, i=0, j=1))\n",
    "    dv_dt = dde.grad.jacobian(y, x, i=0, j=2)\n",
    "    dv_dxx = dde.grad.hessian(y, x, component=0, i=0, j=0)\n",
    "    dv_dyy = dde.grad.hessian(y, x, component=0, i=1, j=1)\n",
    "    dw_dt = dde.grad.jacobian(y, x, i=1, j=2)\n",
    "        ## Coupled PDE+ODE Equations\n",
    "    eq_a = dv_dt -  D*(dv_dxx + dv_dyy) + k*V*(V-a)*(V-1) +W*V \n",
    "    eq_b = dw_dt -  (epsilon + (mu_1*W)/(mu_2+V))*(-W -k*V*(V-b-1))\n",
    "    return [eq_a, eq_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = pde_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 46 points required, but 56 points sampled.\n",
      "Warning: 1000 points required, but 1232 points sampled.\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.050270 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:42:10.069697: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-08 11:42:10.070069: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.\n",
      "Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.\n",
      "'compile' took 0.726343 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pde_data = dde.data.TimePDE(geomtime, pde, input_data,\n",
    "                            num_domain = num_domain, \n",
    "                            num_boundary=num_boundary, \n",
    "                            anchors=observe_train,\n",
    "                            num_test=num_test) \n",
    "model = dde.Model(pde_data, net)\n",
    "model.compile(\"adam\", lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_init(model):\n",
    "    ## Stabilize initialization process by capping the losses\n",
    "    losshistory, _ = model.train(epochs=1)\n",
    "    initial_loss = max(losshistory.loss_train[0])\n",
    "    num_init = 1\n",
    "    while initial_loss>MAX_LOSS or np.isnan(initial_loss):\n",
    "        num_init += 1\n",
    "        model = dde.Model(pde_data, net)\n",
    "        model.compile(\"adam\", lr=lr)\n",
    "        losshistory, _ = model.train(epochs=1)\n",
    "        initial_loss = max(losshistory.loss_train[0])\n",
    "        if num_init > MAX_MODEL_INIT:\n",
    "            raise ValueError('Model initialization phase exceeded the allowed limit')\n",
    "    return 0\n",
    "out_path = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_3_phase(out_path):\n",
    "    init_weights = [0,0,0,0,1]\n",
    "        \n",
    "    ## Initial phase\n",
    "    model.compile(\"adam\", lr=0.0005, loss_weights=init_weights)\n",
    "    losshistory, train_state = model.train(epochs=epochs_init, model_save_path = out_path)\n",
    "    ## Main phase\n",
    "    model.compile(\"adam\", lr=lr)\n",
    "    losshistory, train_state = model.train(epochs=epochs_main, model_save_path = out_path)\n",
    "    ## Final phase\n",
    "    model.compile(\"L-BFGS-B\")\n",
    "    losshistory, train_state = model.train(model_save_path = out_path)\n",
    "    return losshistory, train_state\n",
    "\n",
    "def train_1_phase(out_path):\n",
    "    losshistory, train_state = model.train(epochs=epochs_main, model_save_path = out_path)\n",
    "    return losshistory, train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n",
      "Initializing variables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:42:17.840866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:42:18.042720: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-08 11:42:18.156133: W tensorflow/compiler/jit/kernels/xla_ops.cc:466] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform METAL: NOT_FOUND: could not find registered compiler for platform METAL -- was support for that platform linked in?.  Falling back to TF function call.\n",
      "2023-03-08 11:42:18.157439: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-08 11:42:19.161833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-08 11:42:19.261050: W tensorflow/compiler/jit/kernels/xla_ops.cc:466] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform METAL: NOT_FOUND: could not find registered compiler for platform METAL -- was support for that platform linked in?.  Falling back to TF function call.\n",
      "2023-03-08 11:42:19.261375: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [1.21e+00, 4.00e-01, 2.37e-03, 3.73e-01, 3.90e-01]    [1.13e+00, 4.18e-03, 2.37e-03, 3.73e-01, 3.90e-01]    []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:42:19.772012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-08 11:42:20.067748: W tensorflow/compiler/jit/kernels/xla_ops.cc:466] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform METAL: NOT_FOUND: could not find registered compiler for platform METAL -- was support for that platform linked in?.  Falling back to TF function call.\n",
      "2023-03-08 11:42:20.068161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# stable_init(model)\n",
    "      \n",
    "# losshistory, train_state = train_3_phase(model, out_path)\n",
    "losshistory, train_state = train_1_phase(out_path)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(observe_test)\n",
    "v_pred = pred[:,0:1]\n",
    "rmse_v = np.sqrt(np.square(v_pred - v_test).mean())\n",
    "print(\"V rMSE for test data:\", rmse_v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
